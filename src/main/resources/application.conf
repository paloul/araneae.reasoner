application {
    # The main Akka remoting port that the library communicates over
    akka-remoting-port = 2550
    akka-remoting-port = ${?AKKA.PORT}

    # Timeout for Ask patterns to other agents (remote, child, and even self)
    akka-timeout = 10 seconds
    akka-timeout = ${?AKKA.TIMEOUT}

    # Even when running non-cloud you can create a cluster of akka nodes.
    # Regardless, you still always need a Seed Host to point to. This is
    # usually the first node that comes up online, and it can point to itself.
    # When deploying to cloud and deploy-cloud is true, Akka's dynamic bootstrapping
    # with Kubernetes takes over and dynamically identifies seed hosts.
    akka-seed-host = 127.0.0.1
    akka-seed-host = ${?AKKA.SEED.HOST}
    akka-seed-port = 2550
    akka-seed-port = ${?AKKA.SEED.PORT}

    # Max number of potential nodes in a akka cluster.
    # Mostly applicable if deploying to the cloud, but it can also apply to
    # when creating a cluster with local hard nodes, i.e. laptops.
    # This number should match the max number of machines/nodes that the
    # cluster can scale out to or when running things localhost, the max
    # number of intended laptops for the cluster.
    akka-max-num-nodes = 3
    akka-max-num-nodes = ${?AKKA.MAX-NUM-NODES}

    akka-cluster-name = "araneae"
    akka-cluster-name = ${?AKKA.CLUSTER-NAME}

    # https://doc.akka.io/docs/akka-management/current/bootstrap/
    # https://doc.akka.io/docs/akka-management/current/bootstrap/details.html
    # If you set this to true with the env variable, you must also
    # take care to wipe out the seed-nodes akka.cluster.seed-nodes list
    # with another env variable. As you can't manually define seed-nodes
    # and still have dynamic bootstrapping enabled.
    # If being deployed to cloud we will make use of the bootstrap mechanism
    cloud-deploy = false
    cloud-deploy = ${?CLOUD.DEPLOY}

    # The Akka HTTP Host address and port to bind the HTTP Listener to
    akka-http-host = 0.0.0.0
    akka-http-host = ${?AKKA.HTTP.HOST}
    akka-http-port = 5000
    akka-http-port = ${?AKKA.HTTP.PORT}
}

# For complete documentation and all available options for Akka configuration:
# https://doc.akka.io/docs/akka/current/general/configuration-reference.html
akka {
    # Loggers to register at boot time.
    # Slf4jLogger offers better log performance, according to Akka docs.
    # https://doc.akka.io/docs/akka/current/typed/logging.html#slf4j-backend
    #loggers = ["akka.event.Logging$DefaultLogger"]
    loggers = ["akka.event.slf4j.Slf4jLogger"]
    logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

    # Only in effect during system startup and shutdown, and setting it to OFF as
    # well, ensures that nothing gets logged during system startup or shutdown.
    # This logs only to stdout when first starting and shutting down.
    stdout-loglevel = "OFF"
    # Options: OFF, ERROR, WARNING, INFO, DEBUG
    loglevel = "INFO" # used for logging during normal operation ("loggers")
    loglevel = ${?AKKA.LOG-LEVEL}

    # Log the complete configuration at INFO level when the actor system is started.
    # This is useful when you are uncertain of what configuration is used.
    log-config-on-start = off
    log-config-on-start = ${?AKKA.LOG-CONFIG-ON-START}

    # Log at info level when messages are sent to dead letters, or published to
    # eventStream as `DeadLetter`, `Dropped` or `UnhandledMessage`.
    # Possible values:
    # on: all dead letters are logged
    # off: no logging of dead letters
    # n: positive integer, number of dead letters that will be logged
    log-dead-letters = off
    log-dead-letters = ${?AKKA.LOG-DEAD-LETTERS}

    # Log any messages in dead letter mailboxes when shutting down
    log-dead-letters-during-shutdown = off
    log-dead-letters-during-shutdown = ${?AKKA.LOG-DEAD-LETTERS-DURING-SHUTDWN}

    # List FQCN of extensions which shall be loaded at actor system startup.
    # Should be on the format: 'extensions = ["foo", "bar"]' etc.
    # See the Akka Documentation for more info about Extensions
    extensions = [ ]

    # By default, the JVM is not forcefully stopped.
    # It will be stopped if all non-daemon threads have been terminated.
    # To enable a hard System.exit as a final action you can configure
    # exit-jvm to be on.
    # https://doc.akka.io/docs/akka/current/coordinated-shutdown.html
    coordinated-shutdown {
        exit-jvm = on
    }

    # JVM shutdown, System.exit(-1), in case of a fatal error, such as OutOfMemoryError
    jvm-exit-on-fatal-error = on

    actor {

        # Either one of "local", "remote" or "cluster" or the
        # FQCN of the ActorRefProvider to be used; the below is the built-in default,
        # note that "remote" and "cluster" requires the akka-remote and akka-cluster
        # artifacts to be on the classpath.
        provider = "cluster"

        # Entries for pluggable serializers and their bindings.
        serializers = {
            jackson-json = "akka.serialization.jackson.JacksonJsonSerializer"
            jackson-cbor = "akka.serialization.jackson.JacksonCborSerializer"
        }

        # Class to Serializer binding. You only need to specify the name of an
        # interface or abstract base class of the messages. In case of ambiguity it
        # is using the most specific configured class, or giving a warning and
        # choosing the “first” one.
        #
        # To disable one of the default serializers, assign its class to "none", like
        # "java.io.Serializable" = none
        serialization-bindings = {
            "paloul.araneae.reasoner.util.serializers.CborSerializable" = jackson-cbor
            "paloul.araneae.reasoner.util.serializers.JsonSerializable" = jackson-json
        }

        # Configuration namespace of serialization identifiers.
        # Each serializer implementation must have an entry in the following format:
        # `akka.actor.serialization-identifiers."FQCN" = ID`
        # where `FQCN` is fully qualified class name of the serializer implementation
        # and `ID` is globally unique serializer identifier number.
        # Identifier values from 0 to 40 are reserved for Akka internal usage.
        serialization-identifiers {
            jackson-json = 60
            jackson-cbor = 61
        }

        # SECURITY BEST-PRACTICE is to disable java serialization for its multiple
        # known attack surfaces.
        #
        # This setting is a short-cut to
        # - using DisabledJavaSerializer instead of JavaSerializer
        #
        # Completely disable the use of `akka.serialization.JavaSerialization` by the
        # Akka Serialization extension, instead DisabledJavaSerializer will
        # be inserted which will fail explicitly if attempts to use java serialization are made.
        #
        # The log messages emitted by such serializer SHOULD be treated as potential
        # attacks which the serializer prevented, as they MAY indicate an external operator
        # attempting to send malicious messages intending to use java serialization as attack vector.
        # The attempts are logged with the SECURITY marker.
        #
        # Please note that this option does not stop you from manually invoking java serialization
        #
        allow-java-serialization = off

        # Serializes and deserializes (non-primitive) messages to ensure immutability,
        # this is only intended for testing. Normally, messages sent between local
        # actors (i.e. same JVM) do not undergo serialization.
        # For testing, sometimes, it may be desirable to
        # force serialization on all messages (both remote and local).
        # For performance reasons, never have this on when deployed production or
        # stage.
        serialize-messages = off
        serialize-messages = ${?AKKA.ACTOR.SERIALIZE-MESSAGES}

        debug {
            # enable function of Actor.loggable(), which is to log any received message
            # at DEBUG level, see the “Testing Actor Systems” section of the Akka
            # Documentation at https://akka.io/docs
            receive = off
            receive = ${?AKKA.ACTOR.DEBUG.RECEIVE}

            # enable DEBUG logging of all AutoReceiveMessages (Kill, PoisonPill etc.)
            autoreceive = off
            autoreceive = ${?AKKA.ACTOR.DEBUG.AUTORECEIVE}

            # enable DEBUG logging of actor lifecycle changes
            lifecycle = off
            lifecycle = ${?AKKA.ACTOR.DEBUG.LIFECYCLE}

            # enable DEBUG logging of all LoggingFSMs for events, transitions and timers
            fsm = off
            fsm = ${?AKKA.ACTOR.DEBUG.FSM}

            # enable DEBUG logging of subscription changes on the eventStream
            event-stream = off
            event-stream = ${?AKKA.ACTOR.DEBUG.EVENT-STREAM}

            # enable DEBUG logging of unhandled messages
            unhandled = off
            unhandled = ${?AKKA.ACTOR.DEBUG.UNHANDLED}

            # enable WARN logging of misconfigured routers
            router-misconfiguration = off
            router-misconfiguration = ${?AKKA.ACTOR.DEBUG.ROUTER-MISCONFIG}
        }
    }

    remote {
        artery {
            # Disable artery with this flag
            enabled = on

            # Select the underlying transport implementation.
            # Possible values: aeron-udp, tcp, tls-tcp
            # See https://doc.akka.io/docs/akka/current/remoting-artery.html#selecting-a-transport
            # for the tradeoffs in each transport
            transport = tcp

            # Canonical address is the address other clients should connect to.
            # Artery transport will expect messages to this address.
            canonical.hostname = 127.0.0.1
            canonical.hostname = ${?AKKA.REMOTE.CANONICAL.HOST} # Option to overwrite exits, but no need
            canonical.port = 2550
            canonical.port = ${?AKKA.REMOTE.CANONICAL.PORT} # Option to overwrite exits, but no need

            # Use these settings to bind a network interface to a different address
            # than artery expects messages at. This may be used when running Akka
            # nodes in a separated networks (under NATs or in containers). If canonical
            # and bind addresses are different, then network configuration that relays
            # communications from canonical to bind addresses is expected.
            bind.hostname = 0.0.0.0
            bind.hostname = ${?AKKA.REMOTE.BIND.HOST} # Option to overwrite exits, but no need
            bind.port = 2550
            bind.port = ${?AKKA.REMOTE.BIND.PORT} # Option to overwrite exits, but no need

            # If this is "on", all inbound remote messages will be logged at DEBUG level,
            # if off then they are not logged
            log-received-messages = off
            log-received-messages = ${?AKKA.REMOTE.DEBUG.LOG-RECV-MSGS}

            # If this is "on", all outbound remote messages will be logged at DEBUG level,
            # if off then they are not logged
            log-sent-messages = off
            log-sent-messages = ${?AKKA.REMOTE.DEBUG.LOG-SENT-MSGS}

            # Logging of message types with payload size in bytes larger than
            # this value. Maximum detected size per message type is logged once,
            # with an increase threshold of 10%.
            # By default this feature is turned off. Activate it by setting the property to
            # a value in bytes, such as 1000b. Note that for all messages larger than this
            # limit there will be extra performance and scalability cost.
            log-frame-size-exceeding = off
            log-frame-size-exceeding = ${?AKKA.REMOTE.DEBUG.LOG-FRAME-SIZE-EXCEED}

        }
    }

    cluster {
        # Initial contact points of the cluster.
        # The nodes to join automatically at startup.
        # Comma separated full URIs defined by a string on the form of
        # "akka://system@hostname:port"
        # Leave as empty if the node is supposed to be joined manually.
        # We capture env var defined above under application section to define the starting default seed nodes.
        seed-nodes = [
            "akka://"${application.akka-cluster-name}"@"${application.akka-seed-host}":"${application.akka-seed-port}
        ]

        # The joining of given seed nodes will by default be retried indefinitely until
        # a successful join. That process can be aborted if unsuccessful by defining this
        # timeout. When aborted it will run CoordinatedShutdown, which by default will
        # terminate the ActorSystem. CoordinatedShutdown can also be configured to exit
        # the JVM. It is useful to define this timeout if the seed-nodes are assembled
        # dynamically and a restart with new seed-nodes should be tried after unsuccessful
        # attempts.
        shutdown-after-unsuccessful-join-seed-nodes = 30s

        # Downing must be defined now for Akka version 2.6+.
        # When a cluster member becomes unreachable the leader
        # cannot perform its duties anymore. Members cannot change state,
        # singletons and actors cannot be moved to a different member.
        # In such situations the cluster administrator has to manually
        # down members so the leader can continue its duties.
        #
        # https://doc.akka.io/docs/akka/current/typed/cluster.html#downing
        # https://doc.akka.io/docs/akka/current/split-brain-resolver.html
        # https://doc.akka.io/docs/akka/current/split-brain-resolver.html#strategies
        downing-provider-class = "akka.cluster.sbr.SplitBrainResolverProvider"

        # Minimum required number of members before the leader changes member status
        # of 'Joining' members to 'Up'. Typically used together with
        # 'Cluster.registerOnMemberUp' to defer some action, such as starting actors,
        # until the cluster has reached a certain size.
        min-nr-of-members = 1

        # Enable or disable JMX MBeans for management of the cluster
        jmx.enabled = off

        # Settings for the ClusterShardingExtension
        sharding {

            # When this is set to 'on' the active entity actors will automatically be restarted
            # upon Shard restart. i.e. if the Shard is started on a different ShardRegion
            # due to rebalance or crash.
            #
            # https://doc.akka.io/docs/akka/current/typed/cluster-sharding.html#remembering-entities
            remember-entities = off
            remember-entities = ${?AKKA.CLUSTER.SHARDING.REMEMBER-ENTITIES}

            # When 'remember-entities' is enabled and the state store mode is ddata this controls
            # how the remembered entities and shards are stored. Possible values are "eventsourced" and "ddata"
            # Default is ddata for backwards compatibility.
            remember-entities-store = "ddata"

            # Defines how the coordinator stores its state. Same is also used by the
            # shards for rememberEntities.
            # Valid values are "ddata" or "persistence".
            # "persistence" mode is deprecated
            state-store-mode = "ddata"

            # Set this to a time duration to have sharding passivate entities when they have not
            # received any message in this length of time. Set to 'off' to disable.
            # It is always disabled if `remember-entities` is enabled.
            passivate-idle-entity-after = 120s
            passivate-idle-entity-after = ${?AKKA.CLUSTER.SHARDING.PASSIVATE-IDLE-AFTER}

            # If the shard is remembering entities and an entity stops itself without
            # using passivate. The entity will be restarted after this duration or when
            # the next message for it is received, which ever occurs first.
            entity-restart-backoff = 10 s
            entity-restart-backoff = ${?AKKA.CLUSTER.SHARDING.ENTITY-RESTART-BACKOFF}

            # Rebalance check is performed periodically with this interval.
            rebalance-interval = 10 s
            rebalance-interval = ${?AKKA.CLUSTER.SHARDING.REBALANCE-INTERVAL}

        }
    }

    management {

        # Use localhost address as default, but get hostname if defined in env vars
        http.hostname = 127.0.0.1
        http.hostname = ${?HOST} # If Linux, this HOST var should be defined in bash
        # Use port 8558
        http.port = 8558

        # Bind to 0.0.0.0:8558 'internally':
        http.bind-hostname = 0.0.0.0
        http.bind-port = 8558

        # This will setup helper HTTP APIs that act as health checks. Kubernetes can hit
        # this APIs to check pod status. 
        #
        # https://doc.akka.io/docs/akka-management/current/bootstrap/recipes.html#health-checks
        # https://doc.akka.io/docs/akka-management/current/healthchecks.html#hosting-health-checks-as-an-akka-management-route
        health-checks {
            readiness-path = "ready"
            liveness-path = "alive"
        }

        # Use the kubernetes-api for cluster discovery method. This needs the right permissions
        # in the cluster to work properly.
        #
        # https://doc.akka.io/docs/akka-management/current/bootstrap/kubernetes.html
        # https://doc.akka.io/docs/akka-management/current/kubernetes-deployment/forming-a-cluster.html#akka-cluster-bootstrap
        cluster.bootstrap {
            contact-point-discovery {
                discovery-method = kubernetes-api
            }
        }

    }
}